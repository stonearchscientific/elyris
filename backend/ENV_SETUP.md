# Environment Setup for LLM-Based Parsing

## Choose Your LLM Provider

The system supports **two LLM providers** for document parsing:

### Option 1: Ollama (Recommended for Development) üÜì

**Advantages:**
- ‚úÖ Completely free
- ‚úÖ No API quotas or rate limits
- ‚úÖ Runs locally (no internet required)
- ‚úÖ Fast responses
- ‚úÖ Privacy-focused (data stays on your machine)

**Setup:**
1. Download Ollama from https://ollama.com/download
2. Install and start Ollama
3. Pull a model: `ollama pull llama3.2`
4. Set environment variables in `backend/.env`:
   ```
   LLM_PROVIDER=ollama
   OLLAMA_BASE_URL=http://localhost:11434
   OLLAMA_MODEL=llama3.2
   ```

**Recommended Models:**
- `llama3.2` (3B): Fast, good for development
- `llama3.2:1b`: Very fast, lighter accuracy
- `mistral`: Good balance of speed and accuracy
- `phi3`: Microsoft's efficient model

### Option 2: OpenAI (GPT-4) üí≥

**Advantages:**
- ‚úÖ High accuracy
- ‚úÖ No local setup required
- ‚úÖ Good for production

**Disadvantages:**
- ‚ùå Costs money per API call
- ‚ùå Rate limits and quotas
- ‚ùå Requires internet connection

**Setup:**
1. Get your API key from https://platform.openai.com/api-keys
2. Set environment variables in `backend/.env`:
   ```
   LLM_PROVIDER=openai
   OPENAI_API_KEY=your-key-here
   ```

---

# Environment Setup for LLM-Based Parsing (Legacy OpenAI-only instructions)

## OpenAI API Key Setup

The system uses OpenAI's GPT-4 for intelligent document parsing (sender/recipient extraction).

### Steps:

1. **Get your API key**:
   - Go to https://platform.openai.com/api-keys
   - Click "Create new secret key"
   - Copy the key (you won't see it again!)

2. **Create `.env` file** in the `backend` directory:
   ```bash
   cd backend
   echo "OPENAI_API_KEY=sk-your-actual-key-here" > .env
   ```

3. **Restart the backend** - it will automatically detect and use the key

## How It Works:

**With API Key:**
- ‚úÖ Uses GPT-4o-mini for intelligent block detection
- ‚úÖ Accurately finds sender/recipient regardless of layout
- ‚úÖ Extracts structured fields (name, address, etc.)
- üí∞ ~$0.15 per 1M tokens (very cheap for typical documents)

**Without API Key:**
- ‚ö†Ô∏è Falls back to regex-based heuristics
- ‚ö†Ô∏è Less accurate, depends on document layout
- ‚úÖ Still works, just requires more manual review

## Cost Estimate:

- Typical document: ~1,000 tokens = $0.0002 (fractions of a cent)
- 100 documents/day: ~$0.02/day = $0.60/month
- Very affordable for production use!

## Backend Console Output:

You'll see this when the API key is working:
```
‚úÖ LLM-based parsing enabled
‚úì LLM parsing complete: sender=found, recipient=found
‚úì LLM extracted 5 fields from sender
```

Without the key:
```
‚ö†Ô∏è OPENAI_API_KEY not set. LLM parsing unavailable.
```

## Development & Debugging Options

### Logging

All document parsing activity is logged to `backend/logs/document_parsing_YYYYMMDD.log` with:
- Text extraction steps
- LLM interactions
- Block detection decisions
- Field extraction results
- Validation checks

### Debug Mode

Enable detailed debug output:
```bash
DEBUG_DOCUMENT_PARSING=true
```

This adds verbose logging including:
- Full extracted text previews
- Parsed block contents
- Structured data details

### LLM Validation

Control whether LLM outputs are validated against source text:
```bash
VALIDATE_LLM_EXTRACTIONS=true  # Default: enabled (recommended)
```

When enabled, rejects hallucinated data (addresses not in source text).
Disable for testing to see raw LLM outputs.

### Example .env for Development

```bash
# LLM Provider
LLM_PROVIDER=ollama  # or "openai"
OLLAMA_MODEL=llama3.2:1b
OLLAMA_BASE_URL=http://localhost:11434

# Development Options
DEBUG_DOCUMENT_PARSING=true
VALIDATE_LLM_EXTRACTIONS=true
```

## Testing & Evaluation

See `backend/testing/README.md` for the evaluation framework documentation.

Quick start:
```bash
cd backend
python -m testing.document_eval
```

This runs systematic tests and generates reports for quality tracking.

